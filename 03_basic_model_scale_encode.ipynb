{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../data/scout_data/Case_Study_Data_CLEANED.csv\", sep=',')\n",
    "description = pd.read_csv(\"../data/scout_data/Data_Description.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article_id</td>\n",
       "      <td>unique article identifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product_tier</td>\n",
       "      <td>premium status of the article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>make_name</td>\n",
       "      <td>name of the car manufacturer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>price</td>\n",
       "      <td>price of the article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first_zip_digit</td>\n",
       "      <td>first digit of the zip code of the region the article is offered in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>first_registration_year</td>\n",
       "      <td>year of the first registration of the article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>created_date</td>\n",
       "      <td>creation date of the listing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deleted_date</td>\n",
       "      <td>deletion date of the listing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>search_views</td>\n",
       "      <td>number of times the article has been shown as a search result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>detail_views</td>\n",
       "      <td>number of times the article has been clicked on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stock_days</td>\n",
       "      <td>Time in days between the creation of the listing and the deletion of the listing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ctr</td>\n",
       "      <td>Click through rate calculated as the quotient of detail_views over search_views</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column name  \\\n",
       "0                article_id   \n",
       "1              product_tier   \n",
       "2                 make_name   \n",
       "3                     price   \n",
       "4           first_zip_digit   \n",
       "5   first_registration_year   \n",
       "6              created_date   \n",
       "7              deleted_date   \n",
       "8              search_views   \n",
       "9              detail_views   \n",
       "10               stock_days   \n",
       "11                      ctr   \n",
       "\n",
       "                                                                         description  \n",
       "0                                                          unique article identifier  \n",
       "1                                                      premium status of the article  \n",
       "2                                                       name of the car manufacturer  \n",
       "3                                                               price of the article  \n",
       "4                first digit of the zip code of the region the article is offered in  \n",
       "5                                      year of the first registration of the article  \n",
       "6                                                       creation date of the listing  \n",
       "7                                                       deletion date of the listing  \n",
       "8                      number of times the article has been shown as a search result  \n",
       "9                                    number of times the article has been clicked on  \n",
       "10  Time in days between the creation of the listing and the deletion of the listing  \n",
       "11   Click through rate calculated as the quotient of detail_views over search_views  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 1000)\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78320 entries, 0 to 78319\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   product_tier     78320 non-null  object \n",
      " 1   make_name        78320 non-null  object \n",
      " 2   car_age          78320 non-null  int64  \n",
      " 3   price            78320 non-null  int64  \n",
      " 4   search_views     78320 non-null  float64\n",
      " 5   detail_views     78320 non-null  float64\n",
      " 6   stock_days       78320 non-null  int64  \n",
      " 7   ctr              78320 non-null  object \n",
      " 8   article_id       78320 non-null  int64  \n",
      " 9   first_zip_digit  78320 non-null  int64  \n",
      " 10  created_date     78320 non-null  object \n",
      " 11  deleted_date     78320 non-null  object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.describe()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>car_age</th>\n",
       "      <th>price</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "      <th>article_id</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>11</td>\n",
       "      <td>16750</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.03780329990294403</td>\n",
       "      <td>350625839</td>\n",
       "      <td>5</td>\n",
       "      <td>24.07.18</td>\n",
       "      <td>24.08.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>9</td>\n",
       "      <td>35950</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.06792567773378008</td>\n",
       "      <td>354412280</td>\n",
       "      <td>4</td>\n",
       "      <td>16.08.18</td>\n",
       "      <td>07.10.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>26</td>\n",
       "      <td>11950</td>\n",
       "      <td>3247.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0816137973514013</td>\n",
       "      <td>349572992</td>\n",
       "      <td>3</td>\n",
       "      <td>16.07.18</td>\n",
       "      <td>05.09.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basic</td>\n",
       "      <td>Ford</td>\n",
       "      <td>21</td>\n",
       "      <td>1750</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.014008620689655173</td>\n",
       "      <td>350266763</td>\n",
       "      <td>6</td>\n",
       "      <td>20.07.18</td>\n",
       "      <td>29.10.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>10</td>\n",
       "      <td>26500</td>\n",
       "      <td>490.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.04081632653061224</td>\n",
       "      <td>355688985</td>\n",
       "      <td>3</td>\n",
       "      <td>28.08.18</td>\n",
       "      <td>08.09.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_tier      make_name  car_age  price  search_views  detail_views  \\\n",
       "0        Basic     Mitsubishi       11  16750        3091.0         123.0   \n",
       "1        Basic  Mercedes-Benz        9  35950        3283.0         223.0   \n",
       "2        Basic  Mercedes-Benz       26  11950        3247.0         265.0   \n",
       "3        Basic           Ford       21   1750        1856.0          26.0   \n",
       "4        Basic  Mercedes-Benz       10  26500         490.0          20.0   \n",
       "\n",
       "   stock_days                   ctr  article_id  first_zip_digit created_date  \\\n",
       "0          30   0.03780329990294403   350625839                5     24.07.18   \n",
       "1          52   0.06792567773378008   354412280                4     16.08.18   \n",
       "2          51    0.0816137973514013   349572992                3     16.07.18   \n",
       "3         101  0.014008620689655173   350266763                6     20.07.18   \n",
       "4          12   0.04081632653061224   355688985                3     28.08.18   \n",
       "\n",
       "  deleted_date  \n",
       "0     24.08.18  \n",
       "1     07.10.18  \n",
       "2     05.09.18  \n",
       "3     29.10.18  \n",
       "4     08.09.18  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Predicting expected stock days \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "y = data.stock_days\n",
    "X = data[['price', 'car_age']]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2)\n",
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "The R² score is a measure of how well the model's predictions match the actual values. It indicates the proportion of variance in the dependent variable that is predictable from the independent variables. \n",
    "\n",
    "$R^2 = 1 − \\frac{SS_{tot}}{​SS_{res}}$\n",
    "\n",
    "The R² score (coefficient of determination) ranges between negative values and 1:\n",
    "- 1: The model explains 100% of the variance in the target variable. Perfect fit.\n",
    "- 0: The model is no better than simply predicting the mean of the target variable.\n",
    "- Negative Values: The model is worse than predicting the mean. <br>\n",
    "It means that the model's predictions deviate significantly from the true values, to the point where simply predicting the average target value would give a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score R^2: 0.0107\n",
      "Coefficients: ['0.0001', '-0.3033']\n",
      "Intercept: 37.8922\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score R^2: {reg.score(X_test, y_test):.4f}\")\n",
    "print(f\"Coefficients: {[f'{coef:.4f}' for coef in reg.coef_]}\") \n",
    "print(f\"Intercept: {reg.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomials\n",
    "<detail>\n",
    "\n",
    "A simple linear regression can be extended by constructing polynomial features from the coefficients. In the standard linear regression case, you might have a model that looks like this for two-dimensional data:\n",
    "\n",
    "$$\\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2$$\n",
    "\n",
    "If we want to fit a paraboloid to the data instead of a plane, we can combine the features in second-order polynomials, so that the model looks like this:\n",
    "$$\\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1^2 + w_5 x_2^2$$\n",
    "\n",
    "The (sometimes surprising) observation is that this is still a linear model: to see this, imagine creating a new set of features\n",
    "$$z = [x_1, x_2, x_1 x_2, x_1^2, x_2^2]$$\n",
    "\n",
    "With this re-labeling of the data, our problem can be written\n",
    "$$\\hat{y}(w, z) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5$$\n",
    "\n",
    "We see that the resulting polynomial regression is in the same class of linear models we considered above (i.e. the model is linear in $w$) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.\n",
    "</detail>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 1018.97, Train R^2: 0.0166\n",
      "Test MSE: 1031.01, Test R^2: 0.0123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Creating the polynomial linear regression pipeline\n",
    "pipe = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('linear', LinearRegression(fit_intercept=False))\n",
    "])\n",
    "\n",
    "# Fitting the model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Train MSE: {train_mse:.2f}, Train R^2: {train_r2:.4f}')\n",
    "print(f'Test MSE: {test_mse:.2f}, Test R^2: {test_r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge (L2)\n",
    "The ridge coefficients minimize a penalized residual sum of squares:\n",
    "$$\\min_{w} || X w - y||_2^2 + \\alpha ||w||_{2}^2$$\n",
    "The complexity parameter $\\alpha \\geq 0$ controls the amount of shrinkage: <br>\n",
    "the larger the value of $\\alpha$, the greater the amount of shrinkage and thus the coefficients become more robust to collinearity.\n",
    "\n",
    "It is particularly useful to mitigate the problem of multicollinearity in linear regression, which commonly occurs in models with large numbers of parameters.\n",
    "\n",
    " In general, the method provides improved efficiency in parameter estimation problems in exchange for a tolerable amount of bias (see bias–variance tradeoff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.0141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge(alpha=1.0)  # You can tune alpha via cross-validation\n",
    "ridge_reg.fit(X_train_scaled, y_train)\n",
    "print(f\"R^2: {ridge_reg.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch\n",
    "Exhaustive search over specified parameter values for an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'alpha': 100.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "param_grid = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "ridge = Ridge()\n",
    "grid_search = GridSearchCV(ridge, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(f'Best alpha: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0141\n"
     ]
    }
   ],
   "source": [
    "ridge_best = Ridge(alpha=100)  # You can tune alpha via cross-validation\n",
    "ridge_best.fit(X_train_scaled, y_train)\n",
    "print(f\"{ridge_best.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "Resampling method that iteratively partitions data into mutually exclusive ‘train’ and ‘test’ subsets so model performance can be evaluated on unseen data. \n",
    "\n",
    "This conserves data as avoids the need to hold out a ‘validation’ dataset and accounts for variability as multiple rounds of cross validation are generally performed.\n",
    "\n",
    "This helps in avoiding the randomness associated with the train-test split and gives a better estimate evaluates more robustly how well the model will generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated score: 0.0139\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(ridge_reg, X_test_scaled, y_test, cv=5)\n",
    "print(f'Cross-validated score: {cv_scores.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso (L1)\n",
    "The Lasso is a linear model that estimates sparse coefficients. It prefers solutions with fewer non-zero coefficients, effectively reducing the number of features upon which the given solution is dependent. .\n",
    "\n",
    "Mathematically, it consists of a linear model with an added regularization term. The objective function to minimize is:\n",
    "$$\\min_{w} { \\frac{1}{2n_{\\text{samples}}} ||X w - y||_2 ^ 2 + \\alpha ||w||_1}$$\n",
    "\n",
    "The lasso estimate thus solves the minimization of the least-squares penalty with $(\\alpha ||w||_1)$ added, where $(\\alpha)$ is a constant and $(||w||_1)$ is the $(\\ell_1)$-norm of the coefficient vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso_reg = Lasso(alpha=0.1)  \n",
    "lasso_reg.fit(X_train_scaled, y_train)\n",
    "lasso_reg.score(X_test_scaled, y_test)\n",
    "\n",
    "# search for a good alpha\n",
    "param_grid = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "grid_search = GridSearchCV(lasso_reg, param_grid, cv=5) \n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'Best alpha: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014086\n"
     ]
    }
   ],
   "source": [
    "# Train Lasso with best alpha\n",
    "lasso_best = Ridge(alpha=0.1)  \n",
    "lasso_best.fit(X_train_scaled, y_train)\n",
    "print(f\"{lasso_best.score(X_test_scaled, y_test):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated score: 0.013892\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(lasso_best, X_test_scaled, y_test, cv=5)\n",
    "print(f'Cross-validated score: {cv_scores.mean():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "A random forest fits a number of decision tree regressors on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. \n",
    "\n",
    "Trees in the forest use the best split strategy, i.e. equivalent to passing _splitter=\"best\"_ to the underlying DecisionTreeRegressor. \n",
    "\n",
    "The sub-sample size is controlled with the max_samples parameter if _bootstrap=True_ (default), otherwise the whole dataset is used to build each tree.\n",
    "\n",
    "**n_estimators**: int, default=100, The number of trees in the forest.\n",
    "\n",
    "**criterion**: {“squared_error”, “absolute_error”, “friedman_mse”, “poisson”}, default=”squared_error”\n",
    "\n",
    "**max_dept**:  hint, default=None, The maximum depth of the tree.\n",
    "\n",
    "**n_jobs**: int, default=None, The number of jobs to run in parallel. None means 1,  -1 means using all processors. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated score: -0.2338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100, criterion=\"friedman_mse\", n_jobs=-1)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "rf.score(X_test_scaled, y_test)\n",
    "\n",
    "cv_scores = cross_val_score(rf, X_test_scaled, y_test, cv=5)\n",
    "print(f'Cross-validated score: {cv_scores.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad Fit and Good Fix\n",
    "\n",
    "## Possible reasons for negative R² scores:\n",
    "\n",
    "- **Overfitting**: The model may have memorized the training data well, but performs poorly on the unseen validation sets.  \n",
    "- **Poor Feature Selection**: The input features (X_test_scaled) might not be informative enough for the model to predict the target variable accurately.\n",
    "- **Data Scaling/Preprocessing**: Scaling or preprocessing issues might exist, or the features may need more transformation.\n",
    "- **Data Issues**: The dataset might contain noise, or the relationship between the features and the target variable might not be easily captured by the Random Forest model.\n",
    "- **Model Complexity**: Random Forest models are usually robust, but they can still struggle with certain data types or relationships, particularly if the problem is inherently complex or the data has high variance.\n",
    "\n",
    "## How to address this issue:\n",
    "\n",
    "- **Check for Data Quality**: Make sure there are no data entry errors, missing values, or highly imbalanced classes that could skew the model's learning.\n",
    "- **Tune Hyperparameters**: Use hyperparameter tuning (e.g., GridSearchCV or RandomizedSearchCV) to search for the best hyperparameters for your Random Forest model (like n_estimators, max_depth, etc.).\n",
    "- **Feature Engineering**: Experiment with feature selection, engineering, and transformation. Adding interaction terms, normalizing, or reducing dimensionality with methods like PCA could help.\n",
    "- **Try Other Models**: Sometimes, the Random Forest might not be the best model for the task. You could try other models like Gradient Boosting, XGBoost, or even Linear Regression to see if they perform better.\n",
    "- **Cross-validation strategy**: Make sure your cross-validation is set up correctly and that you are not leaking information between the folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Features - Encoding\n",
    "\n",
    "To integrate categorical features into your model, you need to encode them into a numerical format. \n",
    "\n",
    "The two most common encoding methods for categorical features are One-Hot Encoding and Label Encoding. \n",
    "\n",
    "One-Hot Encoding is typically preferred because it ensures that the model treats the categorical feature as non-ordinal (i.e., the model doesn't assume any inherent order among categories).\n",
    "\n",
    "- StandardScaler() is applied to the numerical features ['price', 'car_age'].\n",
    "\n",
    "- OneHotEncoder(drop='first') is used to encode the categorical features ['product_tier', 'make_name']. \n",
    "\n",
    "- The drop='first' option ensures we avoid the dummy variable trap by dropping one category from each categorical variable.\n",
    "\n",
    "- ColumnTransformer allows you to apply these transformations to the specific columns you selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mitsubishi', 'Mercedes-Benz', 'Ford', 'Volkswagen', 'Fiat',\n",
       "       'Renault', 'Mazda', 'Peugeot', 'Opel', 'Toyota', 'Jaguar', 'Volvo',\n",
       "       'Dacia', 'MINI', 'Porsche', 'Nissan', 'BMW', 'Land Rover', 'Audi',\n",
       "       'Citroen', 'Hyundai', 'Suzuki', 'Alfa Romeo', 'Chevrolet',\n",
       "       'Daewoo', 'Kia', 'Maserati', 'Skoda', 'Caravans-Wohnm', 'SEAT',\n",
       "       'Honda', 'Daihatsu', 'Chrysler', 'smart', 'Saab', 'Jeep',\n",
       "       'Others ', 'Lexus', 'Aixam', 'Ligier', 'Lancia', 'Oldtimer',\n",
       "       'Chatenet', 'Subaru', 'Triumph', 'Ferrari', 'Rolls-Royce', 'Dodge',\n",
       "       'MG', 'Cadillac', 'DS Automobiles', 'Iveco', 'Bentley',\n",
       "       'SsangYong', 'Tesla', 'Trucks-Lkw', 'TVR', 'Aston Martin',\n",
       "       'Abarth', 'HUMMER', 'Lincoln', 'Isuzu', 'Microcar', 'Buick', 'AC',\n",
       "       'Alpina', 'Corvette', 'McLaren', 'Rover', 'Austin', 'De Tomaso',\n",
       "       'FISKER', 'Infiniti', 'Lotus', 'Morgan', 'GMC', 'Oldsmobile',\n",
       "       'Donkervoort', 'Alpine', 'Daimler', 'Lamborghini', 'Grecav',\n",
       "       'Casalini', 'Pontiac', 'MAN', 'Piaggio', 'Amphicar', 'Tata',\n",
       "       'DFSK', 'Kawasaki', 'KTM'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.make_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Basic', 'Premium', 'Plus'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.product_tier.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "y = data['stock_days']\n",
    "X = data[['price', 'car_age', 'product_tier', 'make_name']]\n",
    "\n",
    "# Extract all possible categories from the entire dataset (for both training and test purposes)\n",
    "possible_categories = {\n",
    "    'product_tier': X['product_tier'].unique(),\n",
    "    'make_name': X['make_name'].unique()\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['price', 'car_age']),  # Scale numerical features\n",
    "        ('cat', OneHotEncoder(categories=[possible_categories['product_tier'], \n",
    "                                          possible_categories['make_name']],\n",
    "                              handle_unknown='ignore'), ['product_tier', 'make_name'])  # One-Hot encode categorical features with predefined categories\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline that first applies the preprocessor and then the model\n",
    "pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                 ('regressor', LinearRegression())])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² score: 0.0109\n",
      "Mean Squared Error: 1032.4841\n",
      "Cross-validated score: 0.0067\n"
     ]
    }
   ],
   "source": [
    "print(f\"R² score: {pipe.score(X_test, y_test):.4f}\")\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "\n",
    "cv_scores = cross_val_score(pipe, X_test, y_test, cv=5)\n",
    "print(f'Cross-validated score: {cv_scores.mean():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
